{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x18cce5a7a10>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Author: Robert Guthrie\n",
    "\n",
    "import torch\n",
    "import torch.autograd as autograd\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "torch.manual_seed(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "202385 202385\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# 数据集第一列是单词，第二列是词性，第三列是语法，第四列是实体标签。在NER任务中，只关心第一列和第四列。\n",
    "\n",
    "df = pd.read_csv('data/train.tsv/eng.train',sep=' ')\n",
    "df = df[df.columns[[0,3]]]\n",
    "\n",
    "# 将单个单词根据.分隔成句子\n",
    "df = df.dropna()\n",
    "train_d  =df['-DOCSTART-'].values.tolist()\n",
    "train_t = df['O.1'].values.tolist()\n",
    "\n",
    "print(len(train_d),len(train_t))\n",
    "\n",
    "\n",
    "train_data = []\n",
    "train_tag = []\n",
    "\n",
    "sent = []\n",
    "tag = []\n",
    "for i in range(len(train_d)):\n",
    "    if train_d[i] != \".\":\n",
    "        if train_d != '':\n",
    "            sent.append(train_d[i].lower())\n",
    "            tag.append(train_t[i])\n",
    "    else:\n",
    "        if sent != []:\n",
    "            train_data.append((sent,tag))\n",
    "        sent = []\n",
    "        tag = []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7371"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50934 50934\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('data/test.tsv/eng.testa',sep=' ')\n",
    "df = df[df.columns[[0,3]]]\n",
    "\n",
    "# 将单个单词根据.分隔成句子\n",
    "df = df.dropna()\n",
    "test_d  =df['-DOCSTART-'].values.tolist()\n",
    "test_t = df['O.1'].values.tolist()\n",
    "\n",
    "print(len(test_d),len(test_t))\n",
    "\n",
    "\n",
    "test_data = []\n",
    "test_tag = []\n",
    "\n",
    "sent = []\n",
    "tag = []\n",
    "for i in range(len(test_d)):\n",
    "    if test_d[i] != \".\":\n",
    "        if test_d != '':\n",
    "            sent.append(test_d[i].lower())\n",
    "            tag.append(test_t[i])\n",
    "    else:\n",
    "        if sent != []:\n",
    "            test_data.append((sent,tag))\n",
    "        sent = []\n",
    "        tag = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1874"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "all class number :  9\n"
     ]
    }
   ],
   "source": [
    "from importlib import import_module\n",
    "\n",
    "model_name = 'BiLSTM_CRF'\n",
    "\n",
    "x = import_module('models.' + model_name)\n",
    "config = x.Config()\n",
    "print('all class number : ',config.num_classes)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading exist vocab ... \n",
      "Vocab size: 10002\n",
      "Loading exist vocab ... \n",
      "Vocab size: 10002\n"
     ]
    }
   ],
   "source": [
    "from utils import build_dataset,MyDataset,DataLoader\n",
    "vocab,train_da,train_la = build_dataset(config,train_data)\n",
    "train_dataset = MyDataset(train_da,train_la)\n",
    "train_loader = DataLoader(train_dataset,batch_size=config.batchsize,shuffle=True)\n",
    "\n",
    "vocab,test_da,test_la = build_dataset(config,test_data)\n",
    "test_dataset = MyDataset(test_da,test_la)\n",
    "test_loader = DataLoader(test_dataset,batch_size=config.batchsize,shuffle=True)\n",
    "\n",
    "config.num_vocab = len(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([  986, 10000,   202,   626,     4,  3936,   213,  5771])\n",
      "tensor([2, 0, 4, 0, 0, 0, 4, 0])\n"
     ]
    }
   ],
   "source": [
    "for data,label in train_dataset:\n",
    "    print(data)\n",
    "    print(label)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/3]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7371/7371 [11:17<00:00, 10.88it/s]  \n",
      "100%|██████████| 7371/7371 [03:27<00:00, 35.49it/s]\n",
      "100%|██████████| 1874/1874 [00:54<00:00, 34.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss : 14.0031 ,train acc:0.894 ,dev acc : 0.889 \n",
      "Epoch [2/3]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  9%|▉         | 700/7371 [01:03<10:01, 11.09it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32md:\\08_NLP\\QiuxiPeng\\Task4\\Noll_BiLSTM_CRF\\BiLSTM_CRF.ipynb Cell 9\u001b[0m in \u001b[0;36m<cell line: 5>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/08_NLP/QiuxiPeng/Task4/Noll_BiLSTM_CRF/BiLSTM_CRF.ipynb#X11sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtrain\u001b[39;00m \u001b[39mimport\u001b[39;00m train\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/08_NLP/QiuxiPeng/Task4/Noll_BiLSTM_CRF/BiLSTM_CRF.ipynb#X11sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m model \u001b[39m=\u001b[39m x\u001b[39m.\u001b[39mModel(config)\u001b[39m.\u001b[39mto(config\u001b[39m.\u001b[39mdevice)\n\u001b[1;32m----> <a href='vscode-notebook-cell:/d%3A/08_NLP/QiuxiPeng/Task4/Noll_BiLSTM_CRF/BiLSTM_CRF.ipynb#X11sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m train(config,model,train_dataset,test_dataset,test_dataset)\n",
      "File \u001b[1;32md:\\08_NLP\\QiuxiPeng\\Task4\\Noll_BiLSTM_CRF\\train.py:92\u001b[0m, in \u001b[0;36mtrain\u001b[1;34m(config, model, train_iter, dev_iter, test_iter)\u001b[0m\n\u001b[0;32m     89\u001b[0m trains \u001b[39m=\u001b[39m trains\u001b[39m.\u001b[39mto(config\u001b[39m.\u001b[39mdevice)\n\u001b[0;32m     91\u001b[0m model\u001b[39m.\u001b[39mzero_grad()\n\u001b[1;32m---> 92\u001b[0m loss \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39;49mneg_log_likelihood(trains, labels)\n\u001b[0;32m     93\u001b[0m loss\u001b[39m.\u001b[39mbackward()\n\u001b[0;32m     94\u001b[0m optimizer\u001b[39m.\u001b[39mstep()\n",
      "File \u001b[1;32md:\\08_NLP\\QiuxiPeng\\Task4\\Noll_BiLSTM_CRF\\models\\BiLSTM_CRF.py:207\u001b[0m, in \u001b[0;36mModel.neg_log_likelihood\u001b[1;34m(self, sentence, tags)\u001b[0m\n\u001b[0;32m    205\u001b[0m feats \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_get_lstm_features(sentence)\n\u001b[0;32m    206\u001b[0m \u001b[39m#print(feats.device)\u001b[39;00m\n\u001b[1;32m--> 207\u001b[0m forward_score \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_forward_alg(feats)\n\u001b[0;32m    208\u001b[0m \u001b[39m#print(forward_score.device)\u001b[39;00m\n\u001b[0;32m    209\u001b[0m gold_score \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_score_sentence(feats, tags)\n",
      "File \u001b[1;32md:\\08_NLP\\QiuxiPeng\\Task4\\Noll_BiLSTM_CRF\\models\\BiLSTM_CRF.py:134\u001b[0m, in \u001b[0;36mModel._forward_alg\u001b[1;34m(self, feats)\u001b[0m\n\u001b[0;32m    131\u001b[0m         next_tag_var \u001b[39m=\u001b[39m forward_var \u001b[39m+\u001b[39m trans_score \u001b[39m+\u001b[39m emit_score\n\u001b[0;32m    132\u001b[0m         \u001b[39m# The forward variable for this tag is log-sum-exp of all the\u001b[39;00m\n\u001b[0;32m    133\u001b[0m         \u001b[39m# scores.\u001b[39;00m\n\u001b[1;32m--> 134\u001b[0m         alphas_t\u001b[39m.\u001b[39mappend(log_sum_exp(next_tag_var)\u001b[39m.\u001b[39mview(\u001b[39m1\u001b[39m))\n\u001b[0;32m    135\u001b[0m     forward_var \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mcat(alphas_t)\u001b[39m.\u001b[39mview(\u001b[39m1\u001b[39m, \u001b[39m-\u001b[39m\u001b[39m1\u001b[39m)\n\u001b[0;32m    136\u001b[0m terminal_var \u001b[39m=\u001b[39m forward_var \u001b[39m+\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtransitions[\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtag_to_ix[STOP_TAG]]\n",
      "File \u001b[1;32md:\\08_NLP\\QiuxiPeng\\Task4\\Noll_BiLSTM_CRF\\models\\BiLSTM_CRF.py:68\u001b[0m, in \u001b[0;36mlog_sum_exp\u001b[1;34m(vec)\u001b[0m\n\u001b[0;32m     67\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mlog_sum_exp\u001b[39m(vec):\n\u001b[1;32m---> 68\u001b[0m     max_score \u001b[39m=\u001b[39m vec[\u001b[39m0\u001b[39m, argmax(vec)]\n\u001b[0;32m     69\u001b[0m     max_score_broadcast \u001b[39m=\u001b[39m max_score\u001b[39m.\u001b[39mview(\u001b[39m1\u001b[39m, \u001b[39m-\u001b[39m\u001b[39m1\u001b[39m)\u001b[39m.\u001b[39mexpand(\u001b[39m1\u001b[39m, vec\u001b[39m.\u001b[39msize()[\u001b[39m1\u001b[39m])\n\u001b[0;32m     70\u001b[0m     \u001b[39mreturn\u001b[39;00m max_score \u001b[39m+\u001b[39m \\\n\u001b[0;32m     71\u001b[0m         torch\u001b[39m.\u001b[39mlog(torch\u001b[39m.\u001b[39msum(torch\u001b[39m.\u001b[39mexp(vec \u001b[39m-\u001b[39m max_score_broadcast)))\n",
      "File \u001b[1;32md:\\08_NLP\\QiuxiPeng\\Task4\\Noll_BiLSTM_CRF\\models\\BiLSTM_CRF.py:52\u001b[0m, in \u001b[0;36margmax\u001b[1;34m(vec)\u001b[0m\n\u001b[0;32m     49\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39margmax\u001b[39m(vec):\n\u001b[0;32m     50\u001b[0m     \u001b[39m# return the argmax as a python int\u001b[39;00m\n\u001b[0;32m     51\u001b[0m     _, idx \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mmax(vec, \u001b[39m1\u001b[39m)\n\u001b[1;32m---> 52\u001b[0m     \u001b[39mreturn\u001b[39;00m idx\u001b[39m.\u001b[39;49mitem()\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from train import train\n",
    "\n",
    "model = x.Model(config).to(config.device)\n",
    "\n",
    "train(config,model,train_dataset,test_dataset,test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ML_py38_CU_vs",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
