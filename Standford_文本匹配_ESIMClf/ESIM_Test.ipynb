{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import string \n",
    "\n",
    "'''\n",
    "    单词预处理，将单词全部小写，并且去除标点符号\n",
    "'''\n",
    "def preprocessing(phrase):\n",
    "    lower = [phras.lower() for phras in phrase]    # 将字母全部小写\n",
    "    no_punct = [text.translate(str.maketrans('','',string.punctuation)) for text in lower]   # 去掉标点符号\n",
    "    sp = [text.split() for text in no_punct]\n",
    "    res = [' '.join(lis) for lis in sp]\n",
    "\n",
    "    return res\n",
    "\n",
    "\n",
    "def Get_Preprocess_Data(path):\n",
    "    df = pd.read_csv(path,sep='\\t')\n",
    "    print(\"原始数据标签统计： \")\n",
    "    print(df['gold_label'].value_counts())\n",
    "    df = df[['gold_label','sentence1','sentence2']]\n",
    "    print(\"\")\n",
    "    print(\"去除Nan非法制以及非法标签中... \")\n",
    "    print(\"\")\n",
    "    df = df.dropna()\n",
    "    df = df[df.gold_label.isin(['entailment','neutral','contradiction'])]\n",
    "    print(\"处理后数据标签统计： \")\n",
    "    print(df.gold_label.value_counts())\n",
    "\n",
    "\n",
    "    df['sentence1'] = preprocessing(df['sentence1'])\n",
    "    df['sentence2'] = preprocessing(df['sentence2'])\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader,Dataset,TensorDataset\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "# 定义数据读取类\n",
    "class MyDataset(Dataset):\n",
    "    \"\"\"\n",
    "    步骤一：继承paddle.io.Dataset类\n",
    "    \"\"\"\n",
    "    def __init__(self,df,vocab_path='data/glove.6B/glove.6B.300d.txt',max_sentence_len=64,word_len=300):\n",
    "        \"\"\"\n",
    "        步骤二：实现构造函数，定义数据读取方式，划分训练和测试数据集\n",
    "        \"\"\"\n",
    "        super(MyDataset, self).__init__()\n",
    "        \n",
    "        self.vocab_path = vocab_path\n",
    "        self.wordlen = word_len\n",
    "        self.max_sentence_len = max_sentence_len\n",
    "        _, _, self.word_to_vec_map = self.load_glove_embeddings()\n",
    "\n",
    "        self.text1 = df['sentence1'].values\n",
    "        self.text2 = df['sentence2'].values\n",
    "\n",
    "        #self.data =np.nan_to_num(np.array([self.sentence_to_avg(text) for text in df['Phrase']]),nan=0)\n",
    "\n",
    "\n",
    "        self.label = [['entailment','neutral','contradiction'].index(la) for la in df['gold_label']]\n",
    "\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        \"\"\"\n",
    "        步骤三:实现__getitem__方法,定义指定index时如何获取数据,并返回单条数据(训练数据，对应的标签)\n",
    "        \"\"\"\n",
    "\n",
    "        data1,mask1 = self.sentence_to_avg(self.text1[index])\n",
    "        convert_data1 = np.nan_to_num(np.array(data1),nan=0)\n",
    "        d1 = torch.tensor(convert_data1,dtype=torch.float32)  \n",
    "\n",
    "        data2,mask2 = self.sentence_to_avg(self.text2[index])\n",
    "        convert_data2 = np.nan_to_num(np.array(data2),nan=0)\n",
    "        d2 = torch.tensor(convert_data2,dtype=torch.float32)  \n",
    "\n",
    "        l = torch.tensor(self.label[index],dtype=torch.long)\n",
    "\n",
    "        return (d1,d2,mask1,mask2),l\n",
    "\n",
    "    def __len__(self):\n",
    "        \"\"\"\n",
    "        步骤四:实现__len__方法:返回数据集总数目\n",
    "        \"\"\"\n",
    "        return len(self.label)\n",
    "    \n",
    "\n",
    "    # 将句子转换为向量\n",
    "    def sentence_to_avg(self,sentence):\n",
    "        words = sentence.lower().strip().split()\n",
    "        \n",
    "        se = np.zeros((self.max_sentence_len,self.wordlen))\n",
    "        mask = np.zeros((self.max_sentence_len,))\n",
    "        \n",
    "        for i in range(min(self.max_sentence_len,len(words))):\n",
    "            if words[i] in self.word_to_vec_map.keys():  # 如果不在词表里面，则该向量设置为全零\n",
    "                se[i,:]= self.word_to_vec_map[words[i]]\n",
    "            mask[i] = 1\n",
    "\n",
    "        return se,mask\n",
    "\n",
    "    # 加载GloVe词嵌入\n",
    "    def load_glove_embeddings(self):\n",
    "        with open(self.vocab_path, 'r', encoding='utf-8') as f:\n",
    "            words = set()\n",
    "            word_to_vec_map = {}\n",
    "            \n",
    "            for line in f:\n",
    "                line = line.strip().split()\n",
    "                curr_word = line[0]\n",
    "                words.add(curr_word)\n",
    "                word_to_vec_map[curr_word] = np.array(line[1:], dtype=np.float32)\n",
    "            \n",
    "            i = 1\n",
    "            words_to_index = {}\n",
    "            index_to_words = {}\n",
    "            for w in sorted(words):\n",
    "                words_to_index[w] = i\n",
    "                index_to_words[i] = w\n",
    "                i = i + 1\n",
    "        return words_to_index, index_to_words, word_to_vec_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "原始数据标签统计： \n",
      "entailment       183416\n",
      "contradiction    183187\n",
      "neutral          182764\n",
      "-                   785\n",
      "Name: gold_label, dtype: int64\n",
      "\n",
      "去除Nan非法制以及非法标签中... \n",
      "\n",
      "处理后数据标签统计： \n",
      "entailment       183414\n",
      "contradiction    183185\n",
      "neutral          182762\n",
      "Name: gold_label, dtype: int64\n",
      "原始数据标签统计： \n",
      "entailment       3329\n",
      "contradiction    3278\n",
      "neutral          3235\n",
      "-                 158\n",
      "Name: gold_label, dtype: int64\n",
      "\n",
      "去除Nan非法制以及非法标签中... \n",
      "\n",
      "处理后数据标签统计： \n",
      "entailment       3329\n",
      "contradiction    3278\n",
      "neutral          3235\n",
      "Name: gold_label, dtype: int64\n",
      "原始数据标签统计： \n",
      "entailment       3368\n",
      "contradiction    3237\n",
      "neutral          3219\n",
      "-                 176\n",
      "Name: gold_label, dtype: int64\n",
      "\n",
      "去除Nan非法制以及非法标签中... \n",
      "\n",
      "处理后数据标签统计： \n",
      "entailment       3368\n",
      "contradiction    3237\n",
      "neutral          3219\n",
      "Name: gold_label, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "train_df = Get_Preprocess_Data('../Datasets/snli_1.0/snli_1.0/snli_1.0_train.txt')\n",
    "dev_df = Get_Preprocess_Data('../Datasets/snli_1.0/snli_1.0/snli_1.0_dev.txt')\n",
    "test_df = Get_Preprocess_Data('../Datasets/snli_1.0/snli_1.0/snli_1.0_test.txt')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "all class number :  3\n"
     ]
    }
   ],
   "source": [
    "from importlib import import_module\n",
    "\n",
    "model_name = 'ESIM'\n",
    "\n",
    "x = import_module('models.' + model_name)\n",
    "config = x.Config()\n",
    "print('all class number : ',config.num_classes)\n",
    "\n",
    "train_dataset = MyDataset(train_df,max_sentence_len=64)\n",
    "train_loader = DataLoader(train_dataset,config.batch_size,shuffle=True)\n",
    "\n",
    "dev_dataset = MyDataset(dev_df,max_sentence_len=64)\n",
    "dev_loader = DataLoader(dev_dataset,config.batch_size,shuffle=True)\n",
    "\n",
    "test_dataset = MyDataset(test_df,max_sentence_len=64)\n",
    "test_loader = DataLoader(test_dataset,config.batch_size,shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[-0.2971,  0.0940, -0.0967,  ...,  0.0597, -0.2285,  0.2960],\n",
      "         [-0.5182, -0.1381, -0.4119,  ...,  0.3734, -0.0302,  0.7301],\n",
      "         [-0.3018, -0.1055,  0.1984,  ..., -0.4849, -0.3342,  0.3819],\n",
      "         ...,\n",
      "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]],\n",
      "\n",
      "        [[-0.2971,  0.0940, -0.0967,  ...,  0.0597, -0.2285,  0.2960],\n",
      "         [-0.1035,  0.1513,  0.3629,  ...,  0.3170, -0.4615, -0.1909],\n",
      "         [-0.5316, -0.0945, -0.6418,  ...,  0.2645, -0.0780,  0.4768],\n",
      "         ...,\n",
      "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]],\n",
      "\n",
      "        [[-0.2971,  0.0940, -0.0967,  ...,  0.0597, -0.2285,  0.2960],\n",
      "         [-0.2978, -0.1326, -0.1451,  ...,  0.2761, -0.2832,  0.5055],\n",
      "         [-0.5042,  0.3107,  0.1428,  ..., -0.4410, -0.0087, -0.2264],\n",
      "         ...,\n",
      "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-0.3000,  0.5385, -0.4466,  ..., -0.6067, -0.2888,  0.0256],\n",
      "         [-0.4567,  0.4644, -0.0651,  ...,  0.0124,  0.0991, -0.0563],\n",
      "         [-0.1056,  0.2832,  0.2024,  ...,  0.1049,  0.1180,  0.8231],\n",
      "         ...,\n",
      "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]],\n",
      "\n",
      "        [[-0.2858,  0.2451, -0.2541,  ..., -0.2327, -0.0889,  0.6251],\n",
      "         [ 0.1243, -0.1582, -0.2408,  ...,  0.0409,  0.1790,  0.2955],\n",
      "         [-0.2971,  0.0940, -0.0967,  ...,  0.0597, -0.2285,  0.2960],\n",
      "         ...,\n",
      "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]],\n",
      "\n",
      "        [[-0.2971,  0.0940, -0.0967,  ...,  0.0597, -0.2285,  0.2960],\n",
      "         [-0.2978, -0.1326, -0.1451,  ...,  0.2761, -0.2832,  0.5055],\n",
      "         [-0.4440,  0.1282, -0.2525,  ..., -0.2004, -0.0822, -0.0626],\n",
      "         ...,\n",
      "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]]])\n",
      "tensor([[[ 0.0466,  0.2132, -0.0074,  ...,  0.0091, -0.2099,  0.0539],\n",
      "         [-0.1387, -0.0835,  0.3014,  ..., -0.1358, -0.5220,  0.6770],\n",
      "         [ 0.0385, -0.0398,  0.0827,  ..., -0.3343,  0.0118,  0.0597],\n",
      "         ...,\n",
      "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]],\n",
      "\n",
      "        [[-0.2971,  0.0940, -0.0967,  ...,  0.0597, -0.2285,  0.2960],\n",
      "         [-0.5316, -0.0945, -0.6418,  ...,  0.2645, -0.0780,  0.4768],\n",
      "         [-0.1749,  0.2296,  0.2492,  ..., -0.2413, -0.4040,  0.0547],\n",
      "         ...,\n",
      "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]],\n",
      "\n",
      "        [[-0.2971,  0.0940, -0.0967,  ...,  0.0597, -0.2285,  0.2960],\n",
      "         [-0.5182, -0.1381, -0.4119,  ...,  0.3734, -0.0302,  0.7301],\n",
      "         [ 0.3472,  0.1660, -0.2182,  ..., -0.1974,  0.1213, -0.1625],\n",
      "         ...,\n",
      "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-0.3000,  0.5385, -0.4466,  ..., -0.6067, -0.2888,  0.0256],\n",
      "         [-0.3968,  0.2957,  0.0304,  ...,  0.1683, -0.3588,  0.2549],\n",
      "         [-0.2359,  0.3831,  0.1083,  ..., -0.7919, -0.0860, -0.1466],\n",
      "         ...,\n",
      "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]],\n",
      "\n",
      "        [[ 0.0087,  0.5389,  0.1546,  ..., -0.6230,  0.0117,  0.0086],\n",
      "         [-0.2359,  0.3831,  0.1083,  ..., -0.7919, -0.0860, -0.1466],\n",
      "         [ 0.2205,  0.1123,  0.1700,  ..., -0.0942,  0.2080,  0.0526],\n",
      "         ...,\n",
      "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]],\n",
      "\n",
      "        [[-0.2971,  0.0940, -0.0967,  ...,  0.0597, -0.2285,  0.2960],\n",
      "         [-0.2978, -0.1326, -0.1451,  ...,  0.2761, -0.2832,  0.5055],\n",
      "         [-0.4440,  0.1282, -0.2525,  ..., -0.2004, -0.0822, -0.0626],\n",
      "         ...,\n",
      "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]]])\n",
      "tensor([[1., 1., 1.,  ..., 0., 0., 0.],\n",
      "        [1., 1., 1.,  ..., 0., 0., 0.],\n",
      "        [1., 1., 1.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [1., 1., 1.,  ..., 0., 0., 0.],\n",
      "        [1., 1., 1.,  ..., 0., 0., 0.],\n",
      "        [1., 1., 1.,  ..., 0., 0., 0.]], dtype=torch.float64)\n",
      "tensor([[1., 1., 1.,  ..., 0., 0., 0.],\n",
      "        [1., 1., 1.,  ..., 0., 0., 0.],\n",
      "        [1., 1., 1.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [1., 1., 1.,  ..., 0., 0., 0.],\n",
      "        [1., 1., 1.,  ..., 0., 0., 0.],\n",
      "        [1., 1., 1.,  ..., 0., 0., 0.]], dtype=torch.float64)\n",
      "tensor([2, 0, 2, 0, 0, 1, 2, 2, 2, 2, 2, 0, 1, 2, 2, 2, 1, 2, 1, 2, 0, 0, 0, 2,\n",
      "        1, 2, 2, 2, 1, 0, 2, 2, 1, 0, 2, 1, 1, 0, 0, 0, 2, 0, 1, 1, 0, 2, 2, 1,\n",
      "        1, 0, 2, 2, 0, 1, 1, 0, 2, 1, 2, 0, 2, 1, 2, 0])\n"
     ]
    }
   ],
   "source": [
    "for X,y in dev_loader:\n",
    "    print(X[0])\n",
    "    print(X[1])\n",
    "    print(X[2])\n",
    "    print(X[3])\n",
    "    print(y)\n",
    "    break\n",
    "\n",
    "X = [d.to(config.device) for d in X]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/50]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8584/8584 [11:58<00:00, 11.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss : 0.7625 ,train acc:0.783 , dev loss : 0.7505,dev acc : 0.795 ,test acc : 0.800\n",
      "saving model ...\n",
      "Epoch [2/50]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|▊         | 686/8584 [00:56<10:53, 12.09it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32md:\\08_NLP\\QiuxiPeng\\Task3\\Word2Vec_ESIMClf\\ESIM_Test.ipynb Cell 6\u001b[0m in \u001b[0;36m<cell line: 5>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/08_NLP/QiuxiPeng/Task3/Word2Vec_ESIMClf/ESIM_Test.ipynb#W5sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtrain\u001b[39;00m \u001b[39mimport\u001b[39;00m train\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/08_NLP/QiuxiPeng/Task3/Word2Vec_ESIMClf/ESIM_Test.ipynb#W5sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m model \u001b[39m=\u001b[39m x\u001b[39m.\u001b[39mModel(config)\u001b[39m.\u001b[39mto(config\u001b[39m.\u001b[39mdevice)\n\u001b[1;32m----> <a href='vscode-notebook-cell:/d%3A/08_NLP/QiuxiPeng/Task3/Word2Vec_ESIMClf/ESIM_Test.ipynb#W5sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m train(config,model,train_loader,dev_loader,test_loader)\n",
      "File \u001b[1;32md:\\08_NLP\\QiuxiPeng\\Task3\\Word2Vec_ESIMClf\\train.py:70\u001b[0m, in \u001b[0;36mtrain\u001b[1;34m(config, model, train_iter, dev_iter, test_iter)\u001b[0m\n\u001b[0;32m     68\u001b[0m batch_count \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m\n\u001b[0;32m     69\u001b[0m train_loss_sum  \u001b[39m=\u001b[39m\u001b[39m0.0\u001b[39m\n\u001b[1;32m---> 70\u001b[0m \u001b[39mfor\u001b[39;00m trains, labels \u001b[39min\u001b[39;00m tqdm(train_iter):\n\u001b[0;32m     71\u001b[0m \n\u001b[0;32m     72\u001b[0m     \u001b[39m# 判断输入是否为tuple或list的多输入\u001b[39;00m\n\u001b[0;32m     73\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mtype\u001b[39m(trains) \u001b[39m==\u001b[39m \u001b[39mtuple\u001b[39m \u001b[39mor\u001b[39;00m \u001b[39mtype\u001b[39m(trains) \u001b[39m==\u001b[39m \u001b[39mlist\u001b[39m:\n\u001b[0;32m     74\u001b[0m         trains \u001b[39m=\u001b[39m [d\u001b[39m.\u001b[39mto(config\u001b[39m.\u001b[39mdevice) \u001b[39mfor\u001b[39;00m d \u001b[39min\u001b[39;00m trains]\n",
      "File \u001b[1;32mf:\\ANACONDA\\envs\\ML_py38_CU_vs\\lib\\site-packages\\tqdm\\std.py:1195\u001b[0m, in \u001b[0;36mtqdm.__iter__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1192\u001b[0m time \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_time\n\u001b[0;32m   1194\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m-> 1195\u001b[0m     \u001b[39mfor\u001b[39;00m obj \u001b[39min\u001b[39;00m iterable:\n\u001b[0;32m   1196\u001b[0m         \u001b[39myield\u001b[39;00m obj\n\u001b[0;32m   1197\u001b[0m         \u001b[39m# Update and possibly print the progressbar.\u001b[39;00m\n\u001b[0;32m   1198\u001b[0m         \u001b[39m# Note: does not call self.update(1) for speed optimisation.\u001b[39;00m\n",
      "File \u001b[1;32mf:\\ANACONDA\\envs\\ML_py38_CU_vs\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:681\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    678\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_sampler_iter \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    679\u001b[0m     \u001b[39m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[0;32m    680\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reset()  \u001b[39m# type: ignore[call-arg]\u001b[39;00m\n\u001b[1;32m--> 681\u001b[0m data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_next_data()\n\u001b[0;32m    682\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[0;32m    683\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_dataset_kind \u001b[39m==\u001b[39m _DatasetKind\u001b[39m.\u001b[39mIterable \u001b[39mand\u001b[39;00m \\\n\u001b[0;32m    684\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m \\\n\u001b[0;32m    685\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m>\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[1;32mf:\\ANACONDA\\envs\\ML_py38_CU_vs\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:721\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    719\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_next_data\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[0;32m    720\u001b[0m     index \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_next_index()  \u001b[39m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m--> 721\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_dataset_fetcher\u001b[39m.\u001b[39;49mfetch(index)  \u001b[39m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m    722\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pin_memory:\n\u001b[0;32m    723\u001b[0m         data \u001b[39m=\u001b[39m _utils\u001b[39m.\u001b[39mpin_memory\u001b[39m.\u001b[39mpin_memory(data, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[1;32mf:\\ANACONDA\\envs\\ML_py38_CU_vs\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:49\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[1;34m(self, possibly_batched_index)\u001b[0m\n\u001b[0;32m     47\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mfetch\u001b[39m(\u001b[39mself\u001b[39m, possibly_batched_index):\n\u001b[0;32m     48\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mauto_collation:\n\u001b[1;32m---> 49\u001b[0m         data \u001b[39m=\u001b[39m [\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset[idx] \u001b[39mfor\u001b[39;00m idx \u001b[39min\u001b[39;00m possibly_batched_index]\n\u001b[0;32m     50\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m     51\u001b[0m         data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[1;32mf:\\ANACONDA\\envs\\ML_py38_CU_vs\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:49\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     47\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mfetch\u001b[39m(\u001b[39mself\u001b[39m, possibly_batched_index):\n\u001b[0;32m     48\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mauto_collation:\n\u001b[1;32m---> 49\u001b[0m         data \u001b[39m=\u001b[39m [\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdataset[idx] \u001b[39mfor\u001b[39;00m idx \u001b[39min\u001b[39;00m possibly_batched_index]\n\u001b[0;32m     50\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m     51\u001b[0m         data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset[possibly_batched_index]\n",
      "\u001b[1;32md:\\08_NLP\\QiuxiPeng\\Task3\\Word2Vec_ESIMClf\\ESIM_Test.ipynb Cell 6\u001b[0m in \u001b[0;36mMyDataset.__getitem__\u001b[1;34m(self, index)\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/08_NLP/QiuxiPeng/Task3/Word2Vec_ESIMClf/ESIM_Test.ipynb#W5sZmlsZQ%3D%3D?line=31'>32</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__getitem__\u001b[39m(\u001b[39mself\u001b[39m, index):\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/08_NLP/QiuxiPeng/Task3/Word2Vec_ESIMClf/ESIM_Test.ipynb#W5sZmlsZQ%3D%3D?line=32'>33</a>\u001b[0m     \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/08_NLP/QiuxiPeng/Task3/Word2Vec_ESIMClf/ESIM_Test.ipynb#W5sZmlsZQ%3D%3D?line=33'>34</a>\u001b[0m \u001b[39m    步骤三:实现__getitem__方法,定义指定index时如何获取数据,并返回单条数据(训练数据，对应的标签)\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/08_NLP/QiuxiPeng/Task3/Word2Vec_ESIMClf/ESIM_Test.ipynb#W5sZmlsZQ%3D%3D?line=34'>35</a>\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/d%3A/08_NLP/QiuxiPeng/Task3/Word2Vec_ESIMClf/ESIM_Test.ipynb#W5sZmlsZQ%3D%3D?line=36'>37</a>\u001b[0m     data1,mask1 \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msentence_to_avg(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtext1[index])\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/08_NLP/QiuxiPeng/Task3/Word2Vec_ESIMClf/ESIM_Test.ipynb#W5sZmlsZQ%3D%3D?line=37'>38</a>\u001b[0m     convert_data1 \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mnan_to_num(np\u001b[39m.\u001b[39marray(data1),nan\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/08_NLP/QiuxiPeng/Task3/Word2Vec_ESIMClf/ESIM_Test.ipynb#W5sZmlsZQ%3D%3D?line=38'>39</a>\u001b[0m     d1 \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mtensor(convert_data1,dtype\u001b[39m=\u001b[39mtorch\u001b[39m.\u001b[39mfloat32)  \n",
      "\u001b[1;32md:\\08_NLP\\QiuxiPeng\\Task3\\Word2Vec_ESIMClf\\ESIM_Test.ipynb Cell 6\u001b[0m in \u001b[0;36mMyDataset.sentence_to_avg\u001b[1;34m(self, sentence)\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/08_NLP/QiuxiPeng/Task3/Word2Vec_ESIMClf/ESIM_Test.ipynb#W5sZmlsZQ%3D%3D?line=56'>57</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39msentence_to_avg\u001b[39m(\u001b[39mself\u001b[39m,sentence):\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/08_NLP/QiuxiPeng/Task3/Word2Vec_ESIMClf/ESIM_Test.ipynb#W5sZmlsZQ%3D%3D?line=57'>58</a>\u001b[0m     words \u001b[39m=\u001b[39m sentence\u001b[39m.\u001b[39mlower()\u001b[39m.\u001b[39mstrip()\u001b[39m.\u001b[39msplit()\n\u001b[1;32m---> <a href='vscode-notebook-cell:/d%3A/08_NLP/QiuxiPeng/Task3/Word2Vec_ESIMClf/ESIM_Test.ipynb#W5sZmlsZQ%3D%3D?line=59'>60</a>\u001b[0m     se \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39;49mzeros((\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmax_sentence_len,\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mwordlen))\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/08_NLP/QiuxiPeng/Task3/Word2Vec_ESIMClf/ESIM_Test.ipynb#W5sZmlsZQ%3D%3D?line=60'>61</a>\u001b[0m     mask \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mzeros((\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmax_sentence_len,))\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/08_NLP/QiuxiPeng/Task3/Word2Vec_ESIMClf/ESIM_Test.ipynb#W5sZmlsZQ%3D%3D?line=62'>63</a>\u001b[0m     \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39mmin\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmax_sentence_len,\u001b[39mlen\u001b[39m(words))):\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from train import train\n",
    "\n",
    "model = x.Model(config).to(config.device)\n",
    "\n",
    "train(config,model,train_loader,dev_loader,test_loader)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ML_py38_CU_vs",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "daee3ef7e13f2ba8563ff1f376eed2a156efc7e69720623b8e14dd8374738d01"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
