{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PhraseId</th>\n",
       "      <th>SentenceId</th>\n",
       "      <th>Phrase</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>A series of escapades demonstrating the adage ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>A series of escapades demonstrating the adage ...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>A series</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>A</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>series</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PhraseId  SentenceId                                             Phrase  \\\n",
       "0         1           1  A series of escapades demonstrating the adage ...   \n",
       "1         2           1  A series of escapades demonstrating the adage ...   \n",
       "2         3           1                                           A series   \n",
       "3         4           1                                                  A   \n",
       "4         5           1                                             series   \n",
       "\n",
       "   Sentiment  \n",
       "0          1  \n",
       "1          2  \n",
       "2          2  \n",
       "3          2  \n",
       "4          2  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('data/train.tsv/train.tsv',sep='\\t')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'A series of escapades demonstrating the adage that what is good for the goose is also good for the gander , some of which occasionally amuses but none of which amounts to much of a story .'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Phrase'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PhraseId</th>\n",
       "      <th>SentenceId</th>\n",
       "      <th>Phrase</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>a series of escapades demonstrating the adage ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>a series of escapades demonstrating the adage ...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>a series</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>a</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>series</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PhraseId  SentenceId                                             Phrase  \\\n",
       "0         1           1  a series of escapades demonstrating the adage ...   \n",
       "1         2           1  a series of escapades demonstrating the adage ...   \n",
       "2         3           1                                           a series   \n",
       "3         4           1                                                  a   \n",
       "4         5           1                                             series   \n",
       "\n",
       "   Sentiment  \n",
       "0          1  \n",
       "1          2  \n",
       "2          2  \n",
       "3          2  \n",
       "4          2  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import string \n",
    "\n",
    "'''\n",
    "    单词预处理，将单词全部小写，并且去除标点符号\n",
    "'''\n",
    "def preprocessing(phrase):\n",
    "    lower = [phras.lower() for phras in phrase]    # 将字母全部小写\n",
    "    no_punct = [text.translate(str.maketrans('','',string.punctuation)) for text in lower]   # 去掉标点符号\n",
    "    sp = [text.split() for text in no_punct]\n",
    "    res = [' '.join(lis) for lis in sp]\n",
    "\n",
    "    return res\n",
    "\n",
    "df['Phrase'] = preprocessing(df['Phrase'])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'a series of escapades demonstrating the adage that what is good for the goose is also good for the gander some of which occasionally amuses but none of which amounts to much of a story'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Phrase'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader,Dataset,TensorDataset\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "# 定义数据读取类\n",
    "class MyDataset(Dataset):\n",
    "    \"\"\"\n",
    "    步骤一：继承paddle.io.Dataset类\n",
    "    \"\"\"\n",
    "    def __init__(self,df,vocab_path='data/glove.6B/glove.6B.300d.txt',word_len=300):\n",
    "        \"\"\"\n",
    "        步骤二：实现构造函数，定义数据读取方式，划分训练和测试数据集\n",
    "        \"\"\"\n",
    "        super(MyDataset, self).__init__()\n",
    "        \n",
    "        self.vocab_path = vocab_path\n",
    "        self.wordlen = word_len\n",
    "        _, _, self.word_to_vec_map = self.load_glove_embeddings()\n",
    "\n",
    "\n",
    "        self.data =np.nan_to_num(np.array([self.sentence_to_avg(text) for text in df['Phrase']]),nan=0)\n",
    "\n",
    "\n",
    "        self.label = [la for la in df['Sentiment']]\n",
    "\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        \"\"\"\n",
    "        步骤三:实现__getitem__方法,定义指定index时如何获取数据,并返回单条数据(训练数据，对应的标签)\n",
    "        \"\"\"\n",
    "        d = torch.tensor(self.data[index],dtype=torch.float32)   \n",
    "        l = torch.tensor(self.label[index],dtype=torch.long)\n",
    "\n",
    "        return d,l\n",
    "\n",
    "    def __len__(self):\n",
    "        \"\"\"\n",
    "        步骤四:实现__len__方法:返回数据集总数目\n",
    "        \"\"\"\n",
    "        return self.data.shape[0]\n",
    "    \n",
    "\n",
    "    # 将句子转换为向量\n",
    "    def sentence_to_avg(self,sentence):\n",
    "        words = sentence.lower().strip().split()\n",
    "        \n",
    "        avg = np.zeros(self.wordlen,)\n",
    "        \n",
    "        for w in words:\n",
    "            if w in self.word_to_vec_map.keys():  # 如果不在词表里面，则该向量设置为全零\n",
    "                avg += self.word_to_vec_map[w]\n",
    "        \n",
    "        avg = avg / len(words)\n",
    "        \n",
    "        return avg\n",
    "\n",
    "    # 加载GloVe词嵌入\n",
    "    def load_glove_embeddings(self):\n",
    "        with open(self.vocab_path, 'r', encoding='utf-8') as f:\n",
    "            words = set()\n",
    "            word_to_vec_map = {}\n",
    "            \n",
    "            for line in f:\n",
    "                line = line.strip().split()\n",
    "                curr_word = line[0]\n",
    "                words.add(curr_word)\n",
    "                word_to_vec_map[curr_word] = np.array(line[1:], dtype=np.float32)\n",
    "            \n",
    "            i = 1\n",
    "            words_to_index = {}\n",
    "            index_to_words = {}\n",
    "            for w in sorted(words):\n",
    "                words_to_index[w] = i\n",
    "                index_to_words[i] = w\n",
    "                i = i + 1\n",
    "        return words_to_index, index_to_words, word_to_vec_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_df,dev_df = train_test_split(df,test_size=0.1,random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Administrator\\AppData\\Local\\Temp\\ipykernel_24476\\137047108.py:55: RuntimeWarning: invalid value encountered in true_divide\n",
      "  avg = avg / len(words)\n"
     ]
    }
   ],
   "source": [
    "train_dataset = MyDataset(train_df)\n",
    "train_loader = DataLoader(train_dataset,32,shuffle=True)\n",
    "\n",
    "dev_dataset = MyDataset(dev_df)\n",
    "dev_loader = DataLoader(dev_dataset,32,shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 2.1276e-03, -2.2197e-01,  6.4326e-02, -2.7800e-01, -6.1729e-02,\n",
      "        -1.9566e-01, -1.9008e-01, -4.1553e-02, -1.0493e-01, -5.0115e-01,\n",
      "         1.4418e-01, -6.9267e-02, -2.1731e-01,  1.1661e-02, -2.0700e-04,\n",
      "         9.1448e-02, -1.3151e-01,  1.0881e-02,  1.4332e-01,  4.0839e-02,\n",
      "         5.5388e-02, -1.0229e-01,  1.5621e-01, -1.4271e-02,  1.6602e-02,\n",
      "         8.3729e-02,  1.1173e-01, -2.0185e-01, -1.3646e-02, -1.8593e-01,\n",
      "         1.4688e-01,  1.5315e-01,  1.9309e-01,  1.2108e-01, -4.7660e-01,\n",
      "        -1.2649e-01,  2.2400e-01,  1.9865e-01,  3.9129e-02,  2.7049e-02,\n",
      "         6.7611e-02,  1.2576e-02, -1.3100e-01,  1.5875e-01, -5.0877e-02,\n",
      "        -1.3839e-01, -6.2898e-02,  5.5798e-02, -4.2659e-02, -1.5957e-01,\n",
      "        -2.6173e-03, -1.2671e-01, -7.8191e-02, -6.9357e-02,  9.5163e-02,\n",
      "         1.0222e-01,  7.8807e-02,  1.7340e-01,  2.4614e-02, -9.5348e-02,\n",
      "        -2.8437e-02, -7.5854e-02,  9.2298e-02,  1.0740e-01, -1.6900e-02,\n",
      "        -2.2181e-01, -7.6209e-02, -2.9010e-01,  3.6024e-02, -1.0021e-01,\n",
      "        -3.2230e-02,  6.0531e-02,  1.9639e-01,  1.7032e-01, -8.1518e-02,\n",
      "        -1.9299e-01,  3.0090e-01, -4.5054e-02,  8.6405e-02,  1.8587e-02,\n",
      "         1.2066e-01,  1.2267e-01,  2.4627e-01,  5.5253e-03, -2.1192e-01,\n",
      "         1.3214e-01,  6.3334e-02,  1.5393e-01,  1.8006e-01, -3.7146e-01,\n",
      "        -8.5820e-02,  9.2528e-02,  5.2862e-02,  4.1053e-02,  1.0391e-01,\n",
      "         1.1999e-01,  2.5761e-01, -1.0422e-01,  1.1940e-01, -7.5754e-02,\n",
      "         4.9435e-02, -2.2798e-01, -7.2059e-03,  2.2327e-02, -1.7519e-02,\n",
      "        -1.3473e-01,  3.2929e-02,  2.6504e-02, -2.0936e-02,  7.9905e-02,\n",
      "         7.5767e-02, -2.0245e-01, -1.6995e-01, -9.3527e-02,  1.5064e-01,\n",
      "         4.4921e-02, -2.2153e-01, -9.3916e-02,  5.9089e-02, -8.6700e-02,\n",
      "        -7.0732e-02,  3.0950e-01, -8.3722e-03, -1.5910e-01, -6.3763e-03,\n",
      "        -1.2301e-01, -6.5790e-02,  4.9033e-02,  2.3296e-01,  6.3820e-02,\n",
      "         3.4795e-02, -1.1863e-01,  6.8657e-03, -8.3866e-02,  1.1376e-01,\n",
      "        -1.3379e-01,  8.8672e-02, -2.4095e-01, -1.6599e-01,  1.0965e-01,\n",
      "         1.9387e-01, -3.8873e-02,  3.3181e-01,  1.1690e-01, -2.2019e-01,\n",
      "        -3.9501e-02,  7.1971e-03, -4.1561e-02, -2.5593e-01, -2.8013e-02,\n",
      "         6.3756e-01,  9.8840e-02,  7.4672e-02, -1.3406e-01, -2.0408e-01,\n",
      "         1.9615e-02,  9.8790e-03, -2.6840e-01,  1.3661e-01,  5.9230e-03,\n",
      "        -3.1277e-02, -2.5658e-02,  5.0676e-02, -2.2459e-01, -3.2729e-01,\n",
      "         4.4546e-02, -3.7159e-02,  1.4728e-01,  6.3543e-03,  2.1076e-01,\n",
      "        -1.3360e-01, -1.3732e-01, -4.4665e-01,  1.2805e-02,  1.2933e-01,\n",
      "         3.7679e-01,  9.6056e-02, -1.8812e-01, -1.0334e-01,  1.5782e-01,\n",
      "        -6.8337e-02,  4.5744e-01, -9.9827e-02,  2.7589e-01, -2.4651e-01,\n",
      "         8.7456e-02, -3.7454e-01, -5.8412e-02, -5.2434e-02,  3.4140e-01,\n",
      "        -4.1152e-02,  4.6768e-02, -1.1861e-01,  3.2341e-02, -2.9938e-01,\n",
      "         1.0750e-01,  2.6451e-04,  2.7085e-01,  2.3237e-02, -1.1832e-02,\n",
      "         5.1986e-01, -3.2053e-02,  2.3587e-02,  2.9004e-02,  7.9557e-03,\n",
      "         1.2574e-01,  4.4904e-02, -5.4986e-02,  8.2420e-02, -2.9377e-01,\n",
      "         3.6874e-02, -4.4437e-02,  7.3319e-02,  1.3682e-01, -4.4254e-02,\n",
      "         6.0905e-02,  1.0401e-01,  2.3569e-01, -1.6873e-01, -3.1381e-01,\n",
      "        -1.3363e-01, -1.2030e-01, -1.0536e-01,  8.3420e-02,  3.8324e-02,\n",
      "         1.1949e-01,  1.8286e-01,  2.0780e-02, -6.7411e-04,  7.4732e-02,\n",
      "         3.1382e-02,  1.7122e-01,  5.6026e-02, -1.6140e-01, -1.0374e-01,\n",
      "         7.7903e-02,  1.2937e-01,  4.2482e-02, -3.6416e-02, -5.9145e-02,\n",
      "        -9.5897e-03,  6.7296e-02,  1.1119e-01,  4.8889e-02,  1.2263e-01,\n",
      "        -1.7186e-02,  1.1574e-02, -4.4825e-01, -2.4171e-01,  2.3591e-01,\n",
      "         6.4692e-02, -2.7985e-01, -1.3771e-01, -4.9135e-02,  5.4804e-01,\n",
      "        -1.4418e-01,  8.0037e-02, -1.8655e-01,  6.7315e-02, -1.8749e-02,\n",
      "        -8.6309e-02, -3.0765e-01, -2.6343e-02,  6.0657e-02,  9.3635e-02,\n",
      "        -9.2487e-02, -8.0839e-02,  9.1071e-02,  3.1928e-02, -1.7843e-02,\n",
      "         6.4136e-02, -2.6727e-02, -1.2687e-01, -2.6339e-02, -1.2474e-01,\n",
      "        -8.3884e-02, -6.9184e-01, -4.7717e-02,  1.3681e-01, -8.3344e-03,\n",
      "        -1.4136e-03,  2.8354e-01,  4.1727e-02, -1.6975e-01,  8.6631e-02,\n",
      "         1.5298e-01, -5.2846e-02,  1.0561e-01, -2.0776e-01, -1.4044e-02,\n",
      "         1.6896e-01, -1.1044e-01,  2.9221e-01, -1.2580e-01, -1.8038e-01,\n",
      "         3.3631e-01,  1.6058e-01, -1.6193e-01, -4.8321e-01,  1.5255e-01])\n",
      "tensor(2)\n"
     ]
    }
   ],
   "source": [
    "cnt = 0\n",
    "for trains, labels in train_dataset:\n",
    "    if cnt == 0:\n",
    "\n",
    "        print(trains)\n",
    "        print(labels)\n",
    "    cnt += 1"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "训练NN模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "all class number :  5\n"
     ]
    }
   ],
   "source": [
    "from importlib import import_module\n",
    "\n",
    "model_name = 'NN'\n",
    "\n",
    "x = import_module('models.' + model_name)\n",
    "config = x.Config()\n",
    "print('all class number : ',config.num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/50]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4390/4390 [00:24<00:00, 179.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss : 0.9609 ,train acc:0.602 , dev loss : 0.9788,dev acc : 0.592 \n",
      "saving model ...\n",
      "Epoch [2/50]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4390/4390 [00:23<00:00, 188.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss : 0.9047 ,train acc:0.622 , dev loss : 0.9430,dev acc : 0.608 \n",
      "saving model ...\n",
      "Epoch [3/50]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4390/4390 [00:23<00:00, 186.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss : 0.8572 ,train acc:0.639 , dev loss : 0.9113,dev acc : 0.615 \n",
      "saving model ...\n",
      "Epoch [4/50]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4390/4390 [00:23<00:00, 184.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss : 0.8034 ,train acc:0.664 , dev loss : 0.9019,dev acc : 0.625 \n",
      "saving model ...\n",
      "Epoch [5/50]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4390/4390 [00:23<00:00, 187.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss : 0.7736 ,train acc:0.679 , dev loss : 0.8889,dev acc : 0.634 \n",
      "saving model ...\n",
      "Epoch [6/50]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4390/4390 [00:23<00:00, 187.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss : 0.7400 ,train acc:0.693 , dev loss : 0.8775,dev acc : 0.642 \n",
      "saving model ...\n",
      "Epoch [7/50]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4390/4390 [00:23<00:00, 184.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss : 0.7137 ,train acc:0.702 , dev loss : 0.8909,dev acc : 0.641 \n",
      "Epoch [8/50]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4390/4390 [00:23<00:00, 185.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss : 0.6842 ,train acc:0.714 , dev loss : 0.8965,dev acc : 0.640 \n",
      "Epoch [9/50]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4390/4390 [00:23<00:00, 187.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss : 0.6519 ,train acc:0.728 , dev loss : 0.8886,dev acc : 0.644 \n",
      "Epoch [10/50]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4390/4390 [00:23<00:00, 188.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss : 0.6438 ,train acc:0.734 , dev loss : 0.9026,dev acc : 0.642 \n",
      "Epoch [11/50]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4390/4390 [00:23<00:00, 186.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss : 0.6121 ,train acc:0.746 , dev loss : 0.8967,dev acc : 0.651 \n",
      "Epoch [12/50]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4390/4390 [00:23<00:00, 186.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss : 0.5975 ,train acc:0.749 , dev loss : 0.9429,dev acc : 0.645 \n",
      "Epoch [13/50]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|█▋        | 766/4390 [00:04<00:19, 186.61it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32md:\\08_NLP\\QiuxiPeng\\Task1\\Word2Vec_NNClf\\Word2Vec_NN copy.ipynb Cell 11\u001b[0m in \u001b[0;36m<cell line: 5>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/08_NLP/QiuxiPeng/Task1/Word2Vec_NNClf/Word2Vec_NN%20copy.ipynb#X13sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtrain\u001b[39;00m \u001b[39mimport\u001b[39;00m train\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/08_NLP/QiuxiPeng/Task1/Word2Vec_NNClf/Word2Vec_NN%20copy.ipynb#X13sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m model \u001b[39m=\u001b[39m x\u001b[39m.\u001b[39mModel(config)\u001b[39m.\u001b[39mto(config\u001b[39m.\u001b[39mdevice)\n\u001b[1;32m----> <a href='vscode-notebook-cell:/d%3A/08_NLP/QiuxiPeng/Task1/Word2Vec_NNClf/Word2Vec_NN%20copy.ipynb#X13sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m train(config,model,train_loader,dev_loader,dev_loader)\n",
      "File \u001b[1;32md:\\08_NLP\\QiuxiPeng\\Task1\\Word2Vec_NNClf\\train.py:74\u001b[0m, in \u001b[0;36mtrain\u001b[1;34m(config, model, train_iter, dev_iter, test_iter)\u001b[0m\n\u001b[0;32m     71\u001b[0m     loss\u001b[39m.\u001b[39mbackward()\n\u001b[0;32m     72\u001b[0m     optimizer\u001b[39m.\u001b[39mstep()\n\u001b[1;32m---> 74\u001b[0m     train_loss_sum \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m loss\u001b[39m.\u001b[39;49mcpu()\n\u001b[0;32m     75\u001b[0m     batch_count \u001b[39m=\u001b[39m batch_count \u001b[39m+\u001b[39m \u001b[39m1\u001b[39m\n\u001b[0;32m     76\u001b[0m train_acc,train_loss \u001b[39m=\u001b[39m evaluate_accuracy_gpu(model,train_iter)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from train import train\n",
    "\n",
    "model = x.Model(config).to(config.device)\n",
    "\n",
    "train(config,model,train_loader,dev_loader,dev_loader)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "使用NN模型预测结果"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PhraseId</th>\n",
       "      <th>SentenceId</th>\n",
       "      <th>Phrase</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>156061</td>\n",
       "      <td>8545</td>\n",
       "      <td>An intermittently pleasing but mostly routine ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>156062</td>\n",
       "      <td>8545</td>\n",
       "      <td>An intermittently pleasing but mostly routine ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>156063</td>\n",
       "      <td>8545</td>\n",
       "      <td>An</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>156064</td>\n",
       "      <td>8545</td>\n",
       "      <td>intermittently pleasing but mostly routine effort</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>156065</td>\n",
       "      <td>8545</td>\n",
       "      <td>intermittently pleasing but mostly routine</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PhraseId  SentenceId                                             Phrase\n",
       "0    156061        8545  An intermittently pleasing but mostly routine ...\n",
       "1    156062        8545  An intermittently pleasing but mostly routine ...\n",
       "2    156063        8545                                                 An\n",
       "3    156064        8545  intermittently pleasing but mostly routine effort\n",
       "4    156065        8545         intermittently pleasing but mostly routine"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('data/test.tsv/test.tsv',sep='\\t')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "'''\n",
    "    使用model模型预测test_loader标签\n",
    "'''\n",
    "def predict_test_data(config,model,test_loader):\n",
    "    pred = []\n",
    "    for X,y in tqdm(test_loader):\n",
    "\n",
    "        data = X.to(config.device)\n",
    "        out = model(data)\n",
    "        lab = out.argmax(dim=1) #argmax():返回最大数的索引\n",
    "\n",
    "\n",
    "        pred.extend(lab.detach().cpu().numpy().tolist())\n",
    "    return pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/test.tsv/test.tsv',sep='\\t')\n",
    "df['Phrase'] = preprocessing(df['Phrase'])\n",
    "\n",
    "df['Sentiment'] = [2] * df.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Administrator\\AppData\\Local\\Temp\\ipykernel_24476\\137047108.py:55: RuntimeWarning: invalid value encountered in true_divide\n",
      "  avg = avg / len(words)\n"
     ]
    }
   ],
   "source": [
    "test_dataset = MyDataset(df)\n",
    "test_loader = DataLoader(test_dataset,32,shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load_model name :  output/NN_2023-02-17_13-04-32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2072/2072 [00:02<00:00, 914.44it/s] \n"
     ]
    }
   ],
   "source": [
    "model_name = 'output/NN_2023-02-17_13-04-32'\n",
    "print('load_model name : ',model_name)\n",
    "net = x.Model(config).to(config.device)\n",
    "net.load_state_dict(torch.load(model_name))\n",
    "\n",
    "test_pred = predict_test_data(config,net,test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "Submission_path = 'data/sampleSubmission.csv'\n",
    "submission = pd.read_csv(Submission_path)\n",
    "submission.Sentiment = test_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission.to_csv('NN_submission.csv',index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ML_py38_CU",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "15dfe2a7027fa260522be6aa9f797f27ab9a7dcdfa5dae664afd56517f0ae045"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
