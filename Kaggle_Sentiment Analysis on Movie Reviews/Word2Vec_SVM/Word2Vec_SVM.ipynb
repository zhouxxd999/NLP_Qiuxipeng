{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('data/train.tsv/train.tsv',sep='\\t')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Phrase'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string \n",
    "\n",
    "'''\n",
    "    单词预处理，将单词全部小写，并且去除标点符号\n",
    "'''\n",
    "def preprocessing(phrase):\n",
    "    lower = [phras.lower() for phras in phrase]    # 将字母全部小写\n",
    "    no_punct = [text.translate(str.maketrans('','',string.punctuation)) for text in lower]   # 去掉标点符号\n",
    "    sp = [text.split() for text in no_punct]\n",
    "    res = [' '.join(lis) for lis in sp]\n",
    "\n",
    "    return res\n",
    "\n",
    "df['Phrase'] = preprocessing(df['Phrase'])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Phrase'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader,Dataset,TensorDataset\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "# 定义数据读取类\n",
    "class MyDataset(Dataset):\n",
    "    \"\"\"\n",
    "    步骤一：继承paddle.io.Dataset类\n",
    "    \"\"\"\n",
    "    def __init__(self,df,vocab_path='data/glove.6B/glove.6B.300d.txt',word_len=300):\n",
    "        \"\"\"\n",
    "        步骤二：实现构造函数，定义数据读取方式，划分训练和测试数据集\n",
    "        \"\"\"\n",
    "        super(MyDataset, self).__init__()\n",
    "        \n",
    "        self.vocab_path = vocab_path\n",
    "        self.wordlen = word_len\n",
    "        _, _, self.word_to_vec_map = self.load_glove_embeddings()\n",
    "\n",
    "\n",
    "        self.data =np.nan_to_num(np.array([self.sentence_to_avg(text) for text in df['Phrase']]),nan=0)\n",
    "\n",
    "\n",
    "        self.label = [la for la in df['Sentiment']]\n",
    "\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        \"\"\"\n",
    "        步骤三:实现__getitem__方法,定义指定index时如何获取数据,并返回单条数据(训练数据，对应的标签)\n",
    "        \"\"\"\n",
    "        d = torch.tensor(self.data[index],dtype=torch.float32)   \n",
    "        l = torch.tensor(self.label[index],dtype=torch.long)\n",
    "\n",
    "        return d,l\n",
    "\n",
    "    def __len__(self):\n",
    "        \"\"\"\n",
    "        步骤四:实现__len__方法:返回数据集总数目\n",
    "        \"\"\"\n",
    "        return self.data.shape[0]\n",
    "    \n",
    "\n",
    "    # 将句子转换为向量\n",
    "    def sentence_to_avg(self,sentence):\n",
    "        words = sentence.lower().strip().split()\n",
    "        \n",
    "        avg = np.zeros(self.wordlen,)\n",
    "        \n",
    "        for w in words:\n",
    "            if w in self.word_to_vec_map.keys():  # 如果不在词表里面，则该向量设置为全零\n",
    "                avg += self.word_to_vec_map[w]\n",
    "        \n",
    "        avg = avg / len(words)\n",
    "        \n",
    "        return avg\n",
    "\n",
    "    # 加载GloVe词嵌入\n",
    "    def load_glove_embeddings(self):\n",
    "        with open(self.vocab_path, 'r', encoding='utf-8') as f:\n",
    "            words = set()\n",
    "            word_to_vec_map = {}\n",
    "            \n",
    "            for line in f:\n",
    "                line = line.strip().split()\n",
    "                curr_word = line[0]\n",
    "                words.add(curr_word)\n",
    "                word_to_vec_map[curr_word] = np.array(line[1:], dtype=np.float32)\n",
    "            \n",
    "            i = 1\n",
    "            words_to_index = {}\n",
    "            index_to_words = {}\n",
    "            for w in sorted(words):\n",
    "                words_to_index[w] = i\n",
    "                index_to_words[i] = w\n",
    "                i = i + 1\n",
    "        return words_to_index, index_to_words, word_to_vec_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_df,dev_df = train_test_split(df,test_size=0.1,random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = MyDataset(train_df)\n",
    "train_loader = DataLoader(train_dataset,32,shuffle=True)\n",
    "\n",
    "dev_dataset = MyDataset(dev_df)\n",
    "dev_loader = DataLoader(dev_dataset,32,shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnt = 0\n",
    "for trains, labels in train_dataset:\n",
    "    if cnt == 0:\n",
    "\n",
    "        print(trains)\n",
    "        print(labels)\n",
    "    cnt += 1"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "训练SVM模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "clf = SVC()\n",
    "\n",
    "clf.fit(train_dataset.data,train_dataset.label)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "使用SVM模型预测结果"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train_pred = clf.predict(train_dataset.data)\n",
    "dev_pred = clf.predict(dev_dataset.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "\n",
    "#train_acc = metrics.accuracy_score(train_dataset.label,train_pred)\n",
    "dev_acc = metrics.accuracy_score(dev_dataset.label,dev_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dev_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/test.tsv/test.tsv',sep='\\t')\n",
    "df['Phrase'] = preprocessing(df['Phrase'])\n",
    "\n",
    "test_dataset = MyDataset(df)\n",
    "test_pred = clf.predict(test_dataset.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Submission_path = ''\n",
    "submission = pd.read_csv(Submission_path)\n",
    "submission.Sentiment = test_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# kaggle score  0.627\n",
    "submission.to_csv('my_submission.csv',index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ML_py38_CU_vs",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "daee3ef7e13f2ba8563ff1f376eed2a156efc7e69720623b8e14dd8374738d01"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
